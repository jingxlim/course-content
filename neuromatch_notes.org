#+STARTUP: entitiespretty

* General reflections
- there's no one tool for one problem
- practioners have preferences
* 20JUL14 Neuromatch Week 1 Day 1 QnA
- If all models are wrong, then there's no point to prove falsify models
- if it is a bernouli proccess, the ISI is exponential; but the reverse is not true (i.e. if the ISI is exponential, it might not be due to a bernouli process)
- the "typical" neuron is often not the most representative. It's the neuron that fit most well with theory that people read about.
- asking representation questions ('what' models): you can't be sure that the input you give to the neuron are the correct features
- neurons that don't respond the way we expect them to respond, we think are just noise -- this might not be correct
- whenever we find that a neuron represents something, we give it a name and forget about the representative space hasn't been fully explored
* 20JUL15 Neuromatch Week 1 Day 2 QnA
- just lumping everything unexplainable as noise is dishonest
- you also need to account for noise, to point it to e.g. a random process (e.g. chemical processes, quantum fluctuations in the retina)
- stochastic resonsance is one reason why noise might be helpful
  - white noise in auditory system will help when noise is just below percetual threshold (stochastic facilitation)
- noise is in built into the hardware/implementation; physics, molecules, flow of liquids (in vestibular systems) are noisy
- variational autoencoders: increasing noise builds robustness into adverserial attacks
- ensemble learning, deep learning, or gaussian processes are very flexible and don't require any knowledge about the system you are modelling; that might give you great predictions but not any understanding
- what is a good r^2 values to publish? science is as much as sociological enterprize as it is a logical exercise. in some fields that always deal with noisy phenomenon or if the field is in its infancy, even low r^2 values is interesting.
- How might we effectively use Occam's Razor to narrow down what models are considered "good" or valid in explaining relationships in the data - esp. in cases where it's not clear which models are "simpler"? Is there a more rigorous way of understanding which models make fewer assumptions?
  - there's some theoretical work behind this; you might be able to do it exactly with generative models
  - minimum prescription length: smallest possible pseudocode
  - ensemble model comparisons
  - this paper was mentioned here but not sure why: [[http://www.psy.vanderbilt.edu/courses/psy236/Motion/Motion.17March/Borst(NatNeuro2000).pdf][Models of motion detection by Alexander Borst]]
- at some point, people trust the theory better than the data! e.g. HH model
* 20JUL15 Neuromatch Week 1 Day 3 QnA
- Cross validation, because of multiple splits has a lot of computational cost; AIC you just need to do one run
- Cross validation, because of the splits, you also only use part of the training set
- MLE is more flexible which can makes use of different structures of noise
- MLE you need to write to write out explicitly, you need to say what the nosie to look like; MSE you don't have to make what could be an assumption
- PCA is more similar to MSE in that it is maximizing variance, and there's no need to consider probabilities
- bootstraping is problematic if you have a small dataset where there are not many ways to resample data
- however, bootstraping doesn't make any assumptions
* 20JUL16 Neuromatch Week 1 Day 4 Outro
- GLMs are not flexible enough to solve arbitrary nonlinear problems. For example, the Poisson-GLM was fixed to be log-linear.
- However, this does not mean you shouldn't try it for nonlinear problems! Most nonlinaer problems have a large linear component. GLM is very practical. GLM will be able to predict most of it.
- since it is linear, it's practical and very interpretable
- you can also introduce nonlinear features
* 20JUL16 Neuromatch Week 1 Day 4 QnA
- you typically first start with L2, unless you have aprior reason that L1 is better (e.g. not all neurons should encode some experimental parameter)
- you have lots of non-linearity to choose from, but the nice property of having a convex solution might break
- dimensionality reduction is applying a non-linear transformation to your feature space
* 20JUL16 Neuromatch Week 1 Day 5 QnA
- dimensionality reduction can be used for visualization, denoising and can also be thought about a fundamental bnuilding block of cognition
- Carsen stringer: t-sne and Umap is good for neural data
- differnet methods have different requirements and make different assumptions
- you can use PCs from one half of the data and project to the other half of the data to choose a cutoff for the number of PCs
- how to choose perplexity?
  - preservation of local and global distances
  - e.g. check that if two neural acitivty are correlated, you want to see that these points are close together
  - perplexity should scale with number of data points
- intuition behind t-SNE: map correlation matrix to a 2D space, using a non-linear transformation
  - this helps with keeping correlated neurons together
  - initialisation is important; there's some stochasticity
- Suite2P no longer does PCA first before NMF. It now bins the data first and then looks for sparse events.
- ICA is based on the fact that you have the same signal with different amplitudes at various "sites"
- every dimensionality reduction technique has its own definition about what is signal and what is noise
- people use dimensionality reduction of neural activity as input to BCI, rarely do we use single neuron activity. Sara thinks that the brain uses ensembles for computation, not single neuron.
- What are the open questions in the dimensionality reduction field?
  - we don't know if there are  intrinsic dimensions to be discovered
  - noisy data. as long as you don't know what the ground truth is, you won't know that your method is failing
  - we don't know what is noise
    - noise is something that we cannot explain
    - noise is not correlated to anything else across the population
- you can use trial averaged data to get your eigenvectors. you can then project your noisy trial data onto the trial average to do denoising.
- isomap is able to recover curved surfaces (e.g. cinnamon roll, S-shaped)
- How would you know if your data is nonlinear?
  - make lots of 2D plots
  - think about the external correlates
  - look at the residuals
- Advice:
  - Sara: always plot your data, always start linear. wrong hypothesis will open other avenues for exploration.
  - Byron: don't just take any off-the-shelf dimensionality reduction technique and apply it to your data. test your understanding of the technique with simulate data where you know the ground truth
  - Carsen: there are other kinds of dimensionality reduction techqniues e.g. reduced rank regression -- shared dimensionality to an external correlate
* 20JUL20 Neuromatch Week 2 Day 1 QnA
** If the Brain itself is Bayesian, why does Bayesian logic seem so unituitive? Why is it so difficult for people to understand probabilities?
- type I and type II noise
  - we might be very good making decision based on noisy data, but we  might not be able to say how confident we are about that decision
  - just because the brain is good at something doesn't mean we know what's going on
** Is the brain bayesian, is behavior bayesian, circuits can do bayesian things
- the brain being able to code for uncertainty doesn't mean that the mechanism needs to be bayesian
- the bayesian model being able to explain something well doesn't mean that the model is correct
- Weiji Ma has interesting work comparing between models where he finds that the bayesian model is good, but there are better models that can predict behavior better -- and none of those should be thought of the ground truth
** John Krakauer
- you have some internal model of the world, and how do you reason and plan with this internal representation
- distinguish the mathematical formulaism as a choice
- don't confuse psychological entities (bad) and task variables
** Konrad
- one advantage of the bayesian model is that there's A LOT of literature about it (not every many models have that level of explanatory power)
- another advantage: this is not a HOW model but can act as a bridge as to the mechanism behind our behaviors
* 20JUL21 Neuromatch Week 2 Day 2 QnA
- neurons are not linear, but with some small time period, the system can be approximated as a linear system
- How do you know if a phenomena you observe is linear?
- linear systems is not a model; it is a tool with which you could build models with
- examples of linear systems: optimal feedback system control, decision making, integrate and fire, ring attractors that insect used for navigation
- You can allow the A matrix to change over time, by a process. this is when you find out that a system can be described by a linear system in a local set of time, but not over long times
- you can build a recurrent neural network as a linear system
- if you find dependences and dependences on previous time points, you  can start from linear systems
- linear models are the baseline we compare everything with. if it works well, why make it more complicated? always first consider a linear model.
* 20JUL22 Neuromatch Week 2 Day 3 QnA
- how many states?
  - use cross validation
  - be bayesian about it. infinite hidden markov model
- the standard diffusion model has an upper and lower bound, but the brain implements it between a race between two drifts
- if you are making 2 decisions at a time (what is the color and motion?), the brain does it serially and alernates; it doesn't it both at once
- error trials: when you don't have enough information but still makes a decision. Michael Shadlen: the bounds close in across time.
- even simple systems like sensory systems, it is inferring latent states about the physical world
- knowledge is the consequence of interrogation
* 20JUL23 Neuromatch Week 2 Day 4 QnA
- you can think about control
  - cognitive control
  - control of BMI and prosthetics
  - control of heartbeat, breathing etc
- Bayesian statistics is an umbrella for sensory perception
- Control is an umbrella for motor behavior
- you can formalize a bellman equation not just for maximizing utility, but also for minimizing risk
- whales and doplhins swim very differently than fish; there's no way know what's optimal without knowing your history
- you can always construct a prior for sensory perception that makes the perception optimal, but the question is then whether the prior is good
- people are starting to look for neural correlates of the variables in optimal motor control (e.g. gain might be in the synapses, muscle noise is process noise)
- nystagmus and goldfish eye (goldman and seung)
- Reza: control theory taught to medical students, and how disrupting one region might affect the resulting behavior, which can be explained by control theory. what the students got from it was that control theory is helpful for treating diseases
- hierarchical latent states
  - the brain might makes a model of a model it has, maybe that's why it is so deep
  - stationarity of the environment is not always true. you might have a second latent states to learn from this change and make predictions about that.
- Xaq's recommendations:
  - Laurence Maloney (NYU) experiments about disentangling the uncertainty of one actions and the reward value (which doesn't change)
  - John Doyle  Guaranteed margins of LQG Regulator. Read the abstract!
* 20JUL24 Neuromatch Week 2 Day 5 QnA
- reinforcement learning is trying to  address the normative framework, but RL is one of those frameworks that might be able to connect across levelts
  - why agents learn the way we do? maximize reward
  - what is the algorithm?
  - how neural systems can implement those algorithms
- Richard Sutton has a paper on RL as a stochastic optimal control theory
- RL learn to act by trial and error, while in optimal control theory you are given a model
- model based RL: models are learned and not described as a dynamical systems
- There is a field of RL that doesn't concern an agennt. e.g. they are just trying to make stable systems
- Also a lot of the math in RL comes from dynamical systems
- there are a lot of things (e.g. one-shot learning) where humans still do better than AI and that we don't udnerstand very well, so there's an effort to make AI more human-like
  - use human explanation of what they think they did
  - perhaps why humans are not very good at any one task is because we are good at everything
  - metalearning goes after the right goal of transference and composition
- human like AI
  - human like strategies
  - human like mechanisms
  - human like successes
  - human like biases and failures
- system 1: non-cognitive, system 2: cognitive, functions associated with consciousness
- exploration can be model-free and model-based
  - model free: serendipity
  - model-based: maybe the agent is trying to discover the structure of the world (so this is intentional)
  - model-based: curiousity based exploration
  - model-based: entropy based exploration
  - model-based: where in the world I look so that my RPE gets better
  - noisy TV problem: initially RPE is high, good for explorer; but not good for optimizing because the slope is not going down (when maximizing reward)
- metalearning of exploration strategies, active learning (what are the most representative samples; representative and diversity)
- a lot of many things that are computed in graph theory can be applied in representational learning 
- non-goal directed learning
  - RL field: empowerment, how to change the world
  - Habitual learning
  - also, even if you think something is goal directed, it might not be
* 20JUL27 Neuromatch Week 3 Day 1 QnA
- Failure mode: adding things to your models
  - too complex: didn't learn anything
  - too simple: cannot answer the question
  - a model that reproduces the data doesn't necessarily means it is the right model
- you use graded potentials in retina
  - one reason might be because everything is so close together in the retina
- action potentials
  - saves a lot of power: power is only needed when you're generating AP, but nothing when you are not
- the thing about biology is that it tries to be so many things at the same time
  - you need to be energy efficient
  - small
  - etc
- if you're trying to optimize energy constraints then why is there noise in the brain
  - you don't really know what's noise or not, so you can't really say what you can't correlate with something of the external world is wasted
  - in the retina, light has to pass through multiple layers of cells before hitting the photoreceptors (perhaps it is optimal in other ways, or it is just stuck in an evolutionary dead end)
  - noise is useful to prevent you from local minima
  - rhythms are a noise couteractor! there are noise all over the place, and so are the rhythms
- why model dendrites? aren't they just more units, more "AI neurons", one more layer?
  - spatial effects
  - plasticity
  - and other non-linearities
- Blue Brain Project criticisms
  - constraint the problem by thinking about the problem like an engineer. ask what the brain is trying to solve
  - normative models is complementary to such large scales projects
